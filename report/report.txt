1644
2015
2384
2869
3266

day
3442
3557
3740

Introduction
    A competitive equilibrium is a set of prices and allocations for which 
    We present an algorithm for finding near-CE solutions to the two-good, many trader case, in time linear with the number of traders.


Background


    There is a long history of trial-and-error techniques in this field.
    Walras' original idea for finding equilibrium is called tatonnement, which means ???.
    His approach was to have a centralised auctioneer pick a price, calculate the aggregate supply and demand, then adjust the price accordingly CITE.
    However, Scarf shows that there were initial allocations could be chosen so as to be unstable under this procedure CITE.
    Later research demonstrated that a modified tatonnement procedure could be found, but only if the auctioneer knowledge of all the traders' utility gradients.

    Crockett, Spear and Sunder investigate the divisible goods case under a trading 

    We investigate the multitrader case with only two goods, using randomised bilateral trade.

Model
    This project focuses on simulating a world with two divisible goods that can be exchanged between a number of traders.
    An assignment of goods to traders is called an "allocation".
    Each trader in our world will receive a random initial "endowment" allocation of goods, which they can trade with the others.
    Thus, the allocation will change throughout a "day" of trading.

    The _marginal rate of substitution_ between our two goods will be used throughout to represent price.
    It applies to both actual and potential trades.
    We always express the MRS and gradient (defined below) as units of good 2 per unit good 1.
    For instance, a trade of 4 units of good 1 for 1 unit of good 2 has an MRS of 0.25.

    The _direction_ of a trade is either "Buy" or "Sell", from the perspective of a given trader.
    Direction is also expressed in terms of good 1, so a "Buy" means the trader is gaining good 1 by giving up good 2.

    Utility functions capture the preferences of the actors in an economic model.
    Utility is often identified with the pleasure or satisfaction that an actor gets from a situation.
    The utility is defined such that people always prefer an outcome with higher utility to one with lower 
    In general, a utility function is a function from states of the world to utilities.
    In our case, it will be a function from allocations of our two goods to utilities.

    We will often refer to the gradient of the utility function at a certain allocation.
    This gradient bounds the MRS of an infinitesimally small trade at that point.
    A trader will not buy Good1 in a trade with an MRS that is higher than their gradient, because they would lose utility.  

    For the first part of the project, we use a special kind of utility function called Cobb-Douglass.
    This is x^p*y^(1-p) which is differentiable at all points to *** where x is good 1 and y is good 2.



Implementation

  Single Day

    Each day of the simulation begins by giving each trader their initial endowment.
    Then, pairs of traders are randomly selected to attempt a trade.
    Each trader has access to their utility functions and the gradients of those functions for any allocation.
    From the gradient and any constraints, we calculate two MRSs for each trader, one for each direction.
    The direction of the potential trade (Trader1 buying from T2 or vice versa) is chosen based on the differences between their MRSs.
    The trader with the higher MRS is the one who buys Good 1.

    In the standard model (see section on other utility functions), we calculate a joint MRS by taking the geometric mean of two MRSs.
    This joint MRS is the exchange rate used for the potential.
    We experimented with randomly picking an MRS between the two traders' MRSs, but this was slower and gave worse results.

    Then, we calculate the size of the biggest possible trade that can occur at that MRS.
    A trade can occur if, after reallocation, both traders would have higher utilities.
    We test progressively larger sizes, doubling each time.
    Because the gradient only applies to infinitesimally small sizes, when the MRSs are very similar, the minimum size might not be possible.
    If the largest size is non-zero, the traders exchange the appropriate goods and the process repeats.

    As we go, we keep track of the most recent MRS each trader agreed to trade at. We use this later on to assess the quality of the simulation.

    The simulation of a day ends once traders can make no more mutually beneficial trades.
    To check for this, we track the number of consecutive attempted trades that are rejected. 
    For a simulation with n traders, we wait for n consecutive such empty trades.
    There is a parameter (--finish-count) that can increase or decrease this, but we found in practice that n gives just as good results as 2n or 5n, and is faster.

  Updating Constraints
    In order to have useful changes from one day to the next, the traders must change their behavior.
    They achieve this by updating the constraints on the MRSs they will accept for buying and selling.

    Using the definition of wealth from above, and the last MRS used globally, each trader calculates the wealth they gained or lost during the day.

    Recall that no traders will accept trades that cause them to lose utility. 
    Thus, we can calculate the non-negative utility gain by subtracting the utility of the initial endowment from the utility of the final allocation after a day's worth of trades.

    First, if the trader updated their constraint from the previous day, they compare their wealth and utility gains from today to those from yesterday.
    If the new constraint resulted in less utility or the same utility and less wealth, the constraint is reverted to its previous value.

    When there was not a new constraint on the previous day or the constraint was successful, the trader considers tightening the constraint.
    If they gained wealth during the day, they are happy with the MRSs they are accepting, so they don't make any changes.
    If they lost wealth, they determine whether they were a net buyer or seller of good 1.
    If they were a net buyer, they decrease their buying constraint, which is the highest price they will pay to buy good 1.
    If they were a net seller, they increase their selling constraint instead.
    We will discuss the exact method of tightening in the evaluation section, when we compare different ones.

  Multiple Days
    At the end of each day, we calculate a few statistics about the day's trading. These are used to evaluate the performance of the model.

    The global utility gain, is the percentage increase in utility over the day for all the traders. 
    Because it is a percentage, it can be compared across different starting allocations and numbers of traders.
    It is supposed to increase over time then converge as the traders learn constraints that help them maximize their utility gains.

    The wealth transfer is the sum of the absolute value of wealths gained or lost, divided by the total amount of wealth at the beginning.
    Like above, it is marked to the last price that any trader trades at.
    This should approach 0 over time.
    
    As mentioned above, each trader has a most recent MRS they personally traded at.
    In the ideal case, these all converge to the same value over the day, because if two traders disagree about MRS they can make a mutually beneficial trade.
    To evaluate how close a simulation comes to this ideal, we calculate the standard deviation of the most recent MRS for each trader.
    
    We record the average number of attempted trades per trader in the day.
    We use this as our main method of comparing the running time of different models.
    The elapsed clock time is also recorded, but this is less useful because it isn't comparable across machines.

    Lastly, we calculate constrainedness based on the constraints used by each trader in the past day.
    There are initial buy and sell constraints that every trader begins with.
    This is the percentage of the original range between constraints that traders accept on average.
    We actually use the log range, because the initial constraints vary by orders of magnitude and the plain range would underweight the lower (sell) constraint.
    For example, constrainedness of 100% means that 100% of MRSs (within those initial constraints) are accepted.
    Constrainedness of 5% means that only 5% of MRSs are acceptable on average.
    We expect this to decrease over multiple days, and converge to a low value.

    We track these statistics over many days of trading, and can analyze the results using a diagram like this.
    This is a nice result, since all the stats do what we would expect.
    We call this kind of outcome convergence.

  Convergence
    When designing models, we want to maximize the probabilty that they converge.
    Convergence is a property of a trial of several days of trading.
    Intuitively, as model converges when it stops getting better.
    We define convergence as the point at which the average wealth transfer stops changing, with the caveat that the model does not meet the divergence criteria below.
    More concretely, given a trial that has not diverged, the convergence point is the earliest day where the wealth transfer for all following days is within a threshold.
    Experimentally, we have found that a threshold of 1% seems to capture the examples that match the intuition above.

    We defined convergence on wealth, not utility, because the utility was noiser and less like a monotone function.
    Also, since the goal of this project is to approximate the output of an exact centralised system, we are trying to minimize wealth transfers.
    It is possible that the ideal equilibrium actually has lower utility than the simulation, but the ideal wealth transferred is always zero.
    
    For each model, we record the percentage of trials that converged, as well as the average wealth transfer, utility gain, MRS deviation, and constrainedness at that point.
    We also record those same statistics at the end of the trial, though they are typically very similar.
    The advantage of recording them at the end is that they can be compared across convergent and divergent cases.
    
  Divergence
    The biggest challenge in executing this project was avoiding divergence or death spiral.
    A divergence is characterized by a decrease in utility and an increase in MRS deviation.
    FIGURE is a good example of one.
    It is caused by the model becoming over-constrained, which leads to a reduction in trading volume.
    
    We discovered this phenomenom when we tried the simpler models of constraint choice.
    Every model would diverge in this manner on some trials, even after it had reached an acceptable state.
    We wanted to avoid this in potential models, so we developed a criteria for identifying them automatically.
    
    Formally, a trial is said to diverge if:
        1) Utility gains fall at least 5 percentage points from the first day 
    AND 2) MRS deviation is greater than 0.1 
    We use a moving average to smooth out condition 1.
    
    To avoid divergence, we developed the technique of backtracking, which is discussed below.

  Testing
    Due to the wide parameter space and the length of time to construct experiments, we had to focus on analyzing some parameters, leaving others fixed.
    We tested on models of 100 traders, because they showed the same dynamics as larger models, but still could be tested in only a couple of minutes per trial.
    We ran each trial for 500 days, because most interesting things happened in days 50 to 150, and no model that we looked at diverged or converged after 500 rounds.
    
    We tested 100 trials of each model, using different random allocations for each trial.
    (Except for the stability experiments below)
    However, we seeded the random number generator such that each model ran on the same set of endowments.
    This means that any variations between models was not due to different endowments.
    Multiple trials are necessary because the results are highly dependent on those endowments, which matches the intuition that the point of the project is to simulate economies with different endowments.
    
    After the trials finished, the results were averaged to generate the summary statistics and the convergence/divergence rates.
    For some models with 0% convergence, the quality of convergence metrics are obviously not available.


Experimentation
  Simple Constraint Choice
    First, we investigated three ways of choosing restraints and three ways of reverting them.
    The constraint choice is the action a trader takes when they lose wealth.
    Reversion is when a constraint fails, and a trader needs to relax it.

    Under fixed constraint choice, when a trader loses wealth, they contract their constraint by a fixed percentage.
    This has the advantage of being simple to implement, and fast to evaluate.
    It also would not require knowing the last MRS of the trader.
    We tested this in three variations, with 5%, 10% and 20% constraint factors.
    For example, if the selling constraint was 5.0, a 10% constraint factor would raise that to 5.5.
    
    Last MRS constraint choice means that trader sets the constraint to the last MRS used.
    This could lead to very quick convergence, because the trader would instantly adapt to the market price.
    
    Mean constraint choice results in the trader setting the constraint to the geometric mean of the last price and the current constraint.
    This moves more smoothly than last price and is more adaptive than fixed.
    
    When a trader uses total reversion, they revert to the previous constraint when the current one fails.
    
    Mean reversion is revertint to the geometric mean of the current constraint and the old constraint.
    When combined with mean choice, it is equivalent to binary search over constraints.
    
    Random reversion means that the trader reverts to a random MRS between the current constraint and the old constraint.

    We tested all 15 combinations of constraint choice and reversion.
    The full results are listed in TABLE.
    The results were not particularly encouraging, with 77% of trials diverging and only 15% converging across the board.
    Mean constraint choice was by far the most effective, with 63% converging.
    Mean choice with random reversion had 96% convergence and only 1% divergence.
    However, it took almost three times as many trades to converge as mean-mean.
    Mean-mean was efficient, but only converged 52% of the time.
    Total reversion was slower and less convergent than mean-mean.
    All three had similar MRS divergence and utility gains at convergence.
    Mean-random came out on top with only 3.7% wealth transfers, a little ahead of mean-mean with 4.5%.
    
    Based on these results, we decided to focus on improving versions of the algorithm with mean constraint choice.

  Backtracking

    The main novel idea in this paper is the application of backtracking to this problem.
    Backtracking means looking at past constraints, and if they gave better utility, switching to them with some positive probability.
    The theoretical justification for this is that many variables are being optimized at once and many factors can affect the utility of a trader.
    The trader's own actions, other traders' actions and randomness can all change the utility from day to day.
    When a constraint is added initially, the trader keeps it they gain utility in the day immediately after.
    However, it is possible that the supposed gain in utility actually came from other factors, and the constraint is negative in the long run.
    It is also possible that the constraint might be good in the absence of other traders' behavior, but as they all adapt, the constraint ends up being too tight.
    Thus, it sometimes might be the case that a constraint needs to be relaxed quite a bit to find the optimal solution.

    To implement backtracking, each trader keeps track of their past utilities and constraint values.
    They have a list of integers, called the "backtracks", which are relative indices used for comparison.
    They also have a utility drop threshold and a backtrack probability.
    At every day, they look backwards at their utility gains x days in the past for each x in their list of backtracks.
    If their utility gain has fallen below the threshold since that day in the past, they will reset their constraint to what it was on that day with backtrack probability.

    We tested a variety of different backtracks, probabilities and thresholds on a smaller trial size so we could try more combinations.
    For all of the backtrack tests, we used mean constraint choice and mean reversion.
    The specific locations of the backtracks did not seem to have much effect; for instance, backtracking at 4 is quite similar to backtracking at 9. 
    Because of that, we ended up picking the values of 5, 25 and 100 to represent small, medium, and large backtracks, and only testing those.
    The results from those are in APPENDIX.
    From them, we selected a subset to run full size trials.
    A 99% threshold provided the highest quality results with no significant decrease in speed, so we use that level from here on.
    We chose to run the full tests on probabilities of 50%, 75% and 100%, and backtracks of 5, 25, 5-25 and 5-25-100. 

    Overall, backtracking is a big improvement over the naive constraint choice.
    The results are in TABLE.
    Even the worst performing backtrack model had 83% convergence and 16% divergence.
    The best model, with probability 50% and backtracks at 5, 25, and 100 had 100% convergence, with 34k average trades per trader until convergence.
    Another model (just a single 25 backtrack) also had 100% convergence, but was slower, with 49k trades until convergence.
    The 50%-5-25-100 model was only 29% slower than the mean-mean model without backtracks, but it had much higher rate of convergence, and lower wealth transfers.

    The high convergence percentage, with only 3.5% wealth transfers and tight MRS convergence, makes this version of the algorithm a feasible approximation of the centralised methods. 
    Backtracking greatly reduces the risk of divergence, which was the main issue in getting a decentralized program to be useful.

  Stability
    Stability is a desirable property for any random simulation of a event.
    If the results are very sensitive to the seed of the random number generator, it casts doubt on whether the results reflect the parameters well.
    In our case, we want to get the same results regardless of which pairs of traders are selected to trade.
    To test this, we generated one set of starting allocations and ran many trials with different seeds on the same allocations.
    We tried this with mean-mean in both convergent and divergent cases, as well as with the 50%-5-25-100 backtracking model.

    The results, in TABLE, show that the statistics are stable across different starting seeds.
    The convergent allocations continued to converge 100% of the time, and the divergent allocation did so 100% of the time too.
    It is encouraging that the best backtracking model remained stable, because that suggests that it could be safely used for simulating an allocation in practice.

  Relaxing the Differentiability Assumption
    The system as described relies on the gradient of the utility function to choose a direction and MRS for attempted trades.
    However, it is also possible to procede without the gradient and choose the direction and MRS randomly.
    We can still use the constraints to define the range the MRS is chosen from.
    Because of that, the traders will be able to learn the right MRS across multiple days of trading.
    The trade sizing algorithm works fine with random price and direction, because the utilities of the traders can be queried as before, and the trade will only occur when it increases the utility for both.
    The main effect of this is that many more trades must be attempted per success.

    By giving up on differentiability, the model becomes closer to the real world, where people know their preferences but probably not the derivatives.
    Additionally, it makes it possible to use a wider variety of utility functions, especially piecewise linear ones which are important in the literature. CITE
    There is even the possibility of using non-deterministic utility functions, where the utility function samples a probability distribution.
    This would work fine with the relaxed model as long as the queries were deterministic within individual trades.
    (eg if the oracle says a trade is plus-utility, and so it is accepted, then it must lead to a gain in utility, even if the same terms are rejected on another day) 

    We tested this with the mean-mean constraint model.
    To get it to work, we had to adjust a few parameters. 
    First, we changed the finish count from 1 to 5.
    This meant that the model would wait for more empty trades before finishing a day.
    This was necessary because the ratio of successful to empty trades is so much lower.
    Also, we ran these simulations for more days to get it to converge.
    These changes are appropriate because this algorithm is so much simpler and faster already that it still ran faster than the normal model after the modifications

    The results 

    We also ran it with some other utility functions.


  Comparison to Other Methods
    The main advantage of the techniques in this project over the existing methods available is that the information requirements are much lower. 
    We do not assume that there is a central auctioneer who can query everyone's preferences at the same time.
    This would be unrealistic in many real world markets.

    We unfortunately do not have an easy way of comparing the efficiency of the two since we did not test the centralised methods on the same hardware, and our metric of attempted trades does not apply to a deterministic approach.

    We can say that our approach is linear in the number of traders. 
    This is supported experimentally by running experiments on different numbers of traders.
    The results for the mean-mean simulation on 50 to 500 traders are displayed in FIGURE.
    This reflects the intuition that more traders doesn't change the average number of trades a given trader must interact with.
    Because the trading pairs were randomised to begin with, a trader is indifferent to where the others traders come from.
    

  Possible Improvements
    It would be very useful to compare this directly to the centralised ways of calculating Walrasian equilibria.
    In particular, the utility gains from the actual equilibrium could be compared with the simulated results.
    If it was implemented in the same language, running time could also be compared in practice.

    We only focused on the very simple case of two goods.
    Every centralised model supports more goods, which is more realistic.
    We believe this could be expanded to more goods, but it would take a substantial change to the code and was such outside the scope of the project.
 
